input {
  file {
    path => "C:/dfir/output/parsed_*_skadi/JumpList/*.csv"
    mode => "read"
    start_position => "beginning"
    sincedb_path => "NUL"
    file_completed_action => "log"
    file_completed_log_path => "C:/dfir/output/processed_all.log"
	#file_chunk_size => 524288
    codec => plain { charset => "UTF-8" }
  }
}

filter {

  # ========================================
  # Extract filename (Logstash 8/9 safe)
  # ========================================
  dissect {
    mapping => {
      "[log][file][path]" => "%{?dir}/%{file_name}.csv"
    }
  }

  # ========================================
  # AUTOMATIC DESTINATIONS
  # ========================================
  if "AutomaticDestinations" in [file_name] {

    mutate {
      add_field => {
        "artifact_type" => "jumplist"
        "jumplist_type" => "automatic"
      }
    }

    csv {
      separator => ","
      skip_header => true
      columns => [
        "SourceFile","SourceCreated","SourceModified","SourceAccessed",
        "AppId","AppIdDescription","HasSps","DestListVersion",
        "LastUsedEntryNumber","MRU","EntryNumber",
        "CreationTime","LastModified","Hostname","MacAddress",
        "Path","InteractionCount","PinStatus",
        "FileBirthDroid","FileDroid","VolumeBirthDroid","VolumeDroid",
        "TargetCreated","TargetModified","TargetAccessed",
        "FileSize","RelativePath","WorkingDirectory",
        "FileAttributes","HeaderFlags","DriveType",
        "VolumeSerialNumber","VolumeLabel","LocalPath","CommonPath",
        "TargetIDAbsolutePath","TargetMFTEntryNumber",
        "TargetMFTSequenceNumber","MachineID","MachineMACAddress",
        "TrackerCreatedOn","ExtraBlocksPresent","Arguments","Notes"
      ]
    }
  }

  # ========================================
  # CUSTOM DESTINATIONS
  # ========================================
  else if "CustomDestinations" in [file_name] {

    mutate {
      add_field => {
        "artifact_type" => "jumplist"
        "jumplist_type" => "custom"
      }
    }

    csv {
      separator => ","
      skip_header => true
      columns => [
        "SourceFile","SourceCreated","SourceModified","SourceAccessed",
        "AppId","AppIdDescription","EntryName",
        "TargetCreated","TargetModified","TargetAccessed",
        "FileSize","RelativePath","WorkingDirectory",
        "FileAttributes","HeaderFlags","DriveType",
        "VolumeSerialNumber","VolumeLabel","LocalPath","CommonPath",
        "TargetIDAbsolutePath","TargetMFTEntryNumber",
        "TargetMFTSequenceNumber","MachineID","MachineMACAddress",
        "TrackerCreatedOn","ExtraBlocksPresent","Arguments"
      ]
    }
  }

  # ========================================
  # DATE PARSING (CORRECT FORMAT)
  # ========================================
  date {
    match => ["SourceModified", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }

  date { match => ["SourceCreated", "yyyy-MM-dd HH:mm:ss"] }
  date { match => ["SourceModified", "yyyy-MM-dd HH:mm:ss"] }
  date { match => ["TargetCreated", "yyyy-MM-dd HH:mm:ss"] }
  date { match => ["TargetModified", "yyyy-MM-dd HH:mm:ss"] }
  date { match => ["TargetAccessed", "yyyy-MM-dd HH:mm:ss"] }
  date { match => ["TrackerCreatedOn", "yyyy-MM-dd HH:mm:ss"] }

  mutate {
    remove_field => ["message"]
  }
}

output {
  elasticsearch {
    hosts => ["https://13.233.58.209:9200"]
    user => "elastic"
    password => "wsQcbfozMJF2BEnljEAq"

    ssl_enabled => true
    ssl_verification_mode => "none"
    index => "dfir-jumplist"
  }
}
